{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import apikey\n",
    "from api_key import api_key as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary to store the ids for url requests\n",
    "chart_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of charts for the url requests\n",
    "names = ['retail_gas_price',\n",
    "         'regular_gas_price', 'premium_gas_price', \n",
    "         'europe_brent', 'wti', 'oil_supply', 'crude_oil_production']\n",
    "#list of ids for the url requests\n",
    "series_ids = ['TOTAL.MGUCUUS.M',  \n",
    "              'PET.EMM_EPMR_PTE_NUS_DPG.M', 'PET.EMM_EPMP_PTE_NUS_DPG.M',\n",
    "             'PET.RBRTE.M', 'PET.RWTC.M', 'PET.MTTUA_NUS_1.M', 'TOTAL.PAPRP48.M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chart(names, series_id):\n",
    "    \"\"\"\n",
    "    Takes in a list of names and series_ids\n",
    "    to create a dictionary of \n",
    "    chart names and urls\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    for i, n in enumerate(series_ids):\n",
    "        url = 'http://api.eia.gov/series/?api_key={}&series_id={}'.format(key, series_id[i])\n",
    "        urls.append(url)\n",
    "    \n",
    "    for i, n in enumerate(names):\n",
    "        chart_dict[names[i]] = urls[i]\n",
    "    return chart_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_call(url_value):\n",
    "    \"\"\"\n",
    "    makes an API call\n",
    "    INPUT: the url\n",
    "    OUTPUT: the result of an API call\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(url_value)\n",
    "    \n",
    "    return response.json()['series'][0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dictionary of chart names and urls to a variable\n",
    "chart_dict = get_chart(names, series_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_df(chart_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes in the dictionary of names and urls.\n",
    "    From here it: Makes an API call, Sorts the data to be put in a\n",
    "    DataFrame, & Creates the DataFrame(s)\n",
    "    \"\"\"\n",
    "    \n",
    "    data = make_call(chart_dict[names[count]])\n",
    "    \n",
    "    #sorts the data by date\n",
    "    sorted_data = sorted(data, key = lambda x: x[0])\n",
    "\n",
    "    #adding a dash to the DATE columns to allow it to be parsed\n",
    "    for i, n in enumerate(sorted_data):\n",
    "        sorted_data[i][0] = sorted_data[i][0][:4] + '/' + sorted_data[i][0][4:]\n",
    "    \n",
    "    #creating a dictionary to create a dataframe\n",
    "    dataframe = {'date':[i[0] for i in sorted_data], names[count]:[j[1] for j in sorted_data]}\n",
    "\n",
    "    #checks to see if the DataFrame exists\n",
    "    path = os.path.exists('../Data/GasPrices.csv')\n",
    "    \n",
    "    if path == False:\n",
    "        \n",
    "        #creates an initial dataframe if there isn't one\n",
    "        df1 = pd.DataFrame(dataframe)\n",
    "\n",
    "        df1.to_csv('../Data/GasPrices.csv', index = False)\n",
    "\n",
    "    else:\n",
    "        #creates a new dataframe to be merged with the original\n",
    "        df2 = pd.DataFrame(dataframe)\n",
    "        \n",
    "        df1 = pd.read_csv('../Data/GasPrices.csv')\n",
    "        \n",
    "        gas_data = pd.merge( df1, df2, how = 'left')\n",
    "        \n",
    "        gas_data.to_csv('../Data/GasPrices.csv', index = False) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "#iterating through the charts to have 1 combined dataframe\n",
    "while count != len(names):\n",
    "\n",
    "    data_to_df(chart_dict)\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas = pd.read_csv('../Data/GasPrices.csv')\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.set_index('date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_import_date(x):\n",
    "    '''\n",
    "    This function formats the dates in the imports csv\n",
    "    to make it compatible with the other data.\n",
    "    '''\n",
    "    x=str(x)+'-01-01'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the imports data\n",
    "imports = pd.read_csv('../Data/additional_data/petroleum-consumption.csv', skiprows=4)\n",
    "imports.rename(columns={'year': 'date'}, inplace = True)\n",
    "imports = imports[['date', 'imports']]\n",
    "imports['date'] = imports['date'].apply(format_import_date)\n",
    "imports.to_csv('../Data/additional_data/imports.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports = pd.read_csv('additional_data/imports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of the csv files for exogenous variables\n",
    "csv_list = ['employees_oil_extraction', 'imports', 'federal_gas_tax', 'state_gas_tax', 'inflation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_data(csv_list, count):\n",
    "    \"\"\"\n",
    "    This function takes in list of csvs collected from\n",
    "    https://fred.stlouisfed.org/ & adds them to the main \n",
    "    dataset\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('../Data/additional_data/{}.csv'.format(csv_list[count]))\n",
    "    \n",
    "    #changing the column names to match the main dataset\n",
    "    df.rename(columns={df.columns[0]:'date',df.columns[1]:csv_list[count]}, inplace = True)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['date'] = df['date'].astype('object')\n",
    "    \n",
    "    #opening the main dataset\n",
    "    gas = pd.read_csv('../Data/GasPrices.csv')\n",
    "    gas['date'] = pd.to_datetime(gas['date'])\n",
    "    gas['date'] = gas['date'].astype('object')\n",
    "    \n",
    "    gas_data = pd.merge(gas, df, how = 'left')\n",
    "    gas_data.to_csv('../Data/GasPrices.csv', index = False)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "#iterating through the csvs of exogenous variables to merge them with the dataframe\n",
    "while count != len(csv_list):\n",
    "    \n",
    "    add_new_data(csv_list, count)\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(x):\n",
    "    '''\n",
    "    This function is for the GPR data. It formats the date \n",
    "    column so it can be parsed into a\n",
    "    datetime object\n",
    "    '''\n",
    "    x = x.replace('-','/')\n",
    "    if int(x[-2]) > 3:\n",
    "        x = x[:4] + '19' + x[-2:]\n",
    "    else:\n",
    "        x = x[:4] + '20' + x[-2:]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the main dataset\n",
    "gas = pd.read_csv('../Data/GasPrices.csv')\n",
    "gas['date'] = pd.to_datetime(gas['date'])\n",
    "gas['date'] = gas['date'].astype('object')\n",
    "\n",
    "#opening the GPR dataset\n",
    "gpr = pd.read_csv('../Data/additional_data/gpr_countries.csv')\n",
    "gpr.rename(columns={'Date':'date'}, inplace = True)\n",
    "gpr['date'] = gpr['date'].apply(format_date)\n",
    "gpr['date'] = pd.to_datetime(gpr['date'])\n",
    "gpr['date'] = gpr['date'].astype('object')\n",
    "\n",
    "#concating the two to create the final dataset\n",
    "gas_data = pd.merge(gas, gpr, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the final data\n",
    "gas_data.to_csv('../Data/GasPrices.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
